{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as pandas, numpy, matplotlib, seaborn, and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "import seaborn as sns  # For statistical data visualization\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
    "from sklearn.preprocessing import StandardScaler  # For feature scaling\n",
    "from sklearn.cluster import KMeans  # For clustering\n",
    "from sklearn.metrics import davies_bouldin_score  # For evaluating clustering quality\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset\n",
    "Load Customers.csv, Products.csv, and Transactions.csv into pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "\n",
    "# Load Customers.csv into a DataFrame\n",
    "customers_df = pd.read_csv('Customers.csv')\n",
    "\n",
    "# Load Products.csv into a DataFrame\n",
    "products_df = pd.read_csv('Products.csv')\n",
    "\n",
    "# Load Transactions.csv into a DataFrame\n",
    "transactions_df = pd.read_csv('Transactions.csv')\n",
    "\n",
    "# Display the first few rows of each DataFrame to verify the data\n",
    "print(customers_df.head())\n",
    "print(products_df.head())\n",
    "print(transactions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Handle missing values, data type conversions, and any necessary data cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID              object\n",
      "CustomerName            object\n",
      "Region                  object\n",
      "SignupDate      datetime64[ns]\n",
      "dtype: object\n",
      "ProductID       object\n",
      "ProductName     object\n",
      "Category        object\n",
      "Price          float64\n",
      "dtype: object\n",
      "TransactionID              object\n",
      "CustomerID                 object\n",
      "ProductID                  object\n",
      "TransactionDate    datetime64[ns]\n",
      "Quantity                    int64\n",
      "TotalValue                float64\n",
      "Price                     float64\n",
      "dtype: object\n",
      "  CustomerID        CustomerName         Region SignupDate\n",
      "0      C0001    Lawrence Carroll  South America 2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia 2022-02-13\n",
      "2      C0003      Michael Rivera  South America 2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America 2022-10-09\n",
      "4      C0005         Laura Weber           Asia 2022-08-15\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "  TransactionID CustomerID ProductID     TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067 2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067 2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067 2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067 2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067 2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Handle missing values\n",
    "customers_df.fillna({'CustomerName': 'Unknown', 'Region': 'Unknown'}, inplace=True)\n",
    "products_df.fillna({'ProductName': 'Unknown', 'Category': 'Unknown', 'Price': 0}, inplace=True)\n",
    "transactions_df.fillna({'Quantity': 0, 'TotalValue': 0, 'Price': 0}, inplace=True)\n",
    "\n",
    "# Convert data types\n",
    "customers_df['SignupDate'] = pd.to_datetime(customers_df['SignupDate'])\n",
    "transactions_df['TransactionDate'] = pd.to_datetime(transactions_df['TransactionDate'])\n",
    "products_df['Price'] = products_df['Price'].astype(float)\n",
    "transactions_df['Price'] = transactions_df['Price'].astype(float)\n",
    "transactions_df['TotalValue'] = transactions_df['TotalValue'].astype(float)\n",
    "transactions_df['Quantity'] = transactions_df['Quantity'].astype(int)\n",
    "\n",
    "# Verify data types\n",
    "print(customers_df.dtypes)\n",
    "print(products_df.dtypes)\n",
    "print(transactions_df.dtypes)\n",
    "\n",
    "# Additional data cleaning steps if necessary\n",
    "# For example, removing duplicates\n",
    "customers_df.drop_duplicates(subset='CustomerID', keep='first', inplace=True)\n",
    "products_df.drop_duplicates(subset='ProductID', keep='first', inplace=True)\n",
    "transactions_df.drop_duplicates(subset='TransactionID', keep='first', inplace=True)\n",
    "\n",
    "# Display the first few rows of each DataFrame after preprocessing\n",
    "print(customers_df.head())\n",
    "print(products_df.head())\n",
    "print(transactions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lookalike Model\n",
    "Build a Lookalike Model that recommends 3 similar customers based on their profile and transaction history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookalike Model\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Analyze customer transaction behavior\n",
    "customer_transactions = transactions_df.groupby('CustomerID').agg({\n",
    "    'TransactionID': 'count',\n",
    "    'TotalValue': 'sum',\n",
    "    'Quantity': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge with customer data\n",
    "customer_analysis_df = customers_df.merge(customer_transactions, on='CustomerID')\n",
    "# Average transaction value per customer\n",
    "customer_analysis_df['AvgTransactionValue'] = customer_analysis_df['TotalValue'] / customer_analysis_df['TransactionID']\n",
    "\n",
    "# Prepare the data for the lookalike model\n",
    "customer_features = customer_analysis_df[['CustomerID', 'Region', 'TotalValue', 'Quantity', 'AvgTransactionValue']]\n",
    "customer_features = pd.get_dummies(customer_features, columns=['Region'])\n",
    "\n",
    "# Fit the Nearest Neighbors model\n",
    "nn_model = NearestNeighbors(n_neighbors=4, metric='euclidean')\n",
    "nn_model.fit(customer_features.drop(columns=['CustomerID']))\n",
    "\n",
    "# Function to find lookalikes for a given customer\n",
    "def find_lookalikes(customer_id):\n",
    "    customer_index = customer_features[customer_features['CustomerID'] == customer_id].index[0]\n",
    "    distances, indices = nn_model.kneighbors([customer_features.drop(columns=['CustomerID']).iloc[customer_index]])\n",
    "    lookalikes = customer_features.iloc[indices[0][1:]]\n",
    "    lookalikes['SimilarityScore'] = 1 / (1 + distances[0][1:])\n",
    "    return lookalikes[['CustomerID', 'SimilarityScore']]\n",
    "\n",
    "# Generate lookalikes for the first 20 customers\n",
    "lookalike_results = {}\n",
    "for customer_id in customers_df['CustomerID'][:20]:\n",
    "    lookalike_results[customer_id] = find_lookalikes(customer_id).values.tolist()\n",
    "\n",
    "# Save the lookalike results to a CSV file\n",
    "lookalike_df = pd.DataFrame.from_dict(lookalike_results, orient='index')\n",
    "lookalike_df.to_csv('FirstName_LastName_Lookalike.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Create features from customer and product information for the Lookalike Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName SignupDate   Recency  Frequency  Monetary  \\\n",
      "0      C0001    Lawrence Carroll 2022-07-10 -0.266933  -0.011458 -0.061701   \n",
      "1      C0002      Elizabeth Lutz 2022-02-13 -0.690872  -0.467494 -0.877744   \n",
      "2      C0003      Michael Rivera 2024-03-07  0.722260  -0.467494 -0.405857   \n",
      "3      C0004  Kathleen Rodriguez 2022-10-09 -0.987630   1.356650  1.032547   \n",
      "4      C0005         Laura Weber 2022-08-15 -0.281064  -0.923530 -0.783929   \n",
      "\n",
      "   Region_Asia  Region_Europe  Region_North America  Region_South America  \n",
      "0        False          False                 False                  True  \n",
      "1         True          False                 False                 False  \n",
      "2        False          False                 False                  True  \n",
      "3        False          False                 False                  True  \n",
      "4         True          False                 False                 False  \n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Create features from customer and product information for the Lookalike Model\n",
    "\n",
    "# Calculate the recency of the last transaction for each customer\n",
    "latest_transaction_date = transactions_df.groupby('CustomerID')['TransactionDate'].max().reset_index()\n",
    "latest_transaction_date.columns = ['CustomerID', 'LastTransactionDate']\n",
    "latest_transaction_date['Recency'] = (transactions_df['TransactionDate'].max() - latest_transaction_date['LastTransactionDate']).dt.days\n",
    "\n",
    "# Calculate the frequency of transactions for each customer\n",
    "transaction_frequency = transactions_df.groupby('CustomerID')['TransactionID'].count().reset_index()\n",
    "transaction_frequency.columns = ['CustomerID', 'Frequency']\n",
    "\n",
    "# Calculate the monetary value of transactions for each customer\n",
    "transaction_monetary = transactions_df.groupby('CustomerID')['TotalValue'].sum().reset_index()\n",
    "transaction_monetary.columns = ['CustomerID', 'Monetary']\n",
    "\n",
    "# Merge the recency, frequency, and monetary features with the customer data\n",
    "customer_features = customers_df.merge(latest_transaction_date[['CustomerID', 'Recency']], on='CustomerID')\n",
    "customer_features = customer_features.merge(transaction_frequency[['CustomerID', 'Frequency']], on='CustomerID')\n",
    "customer_features = customer_features.merge(transaction_monetary[['CustomerID', 'Monetary']], on='CustomerID')\n",
    "\n",
    "# One-hot encode the 'Region' feature\n",
    "customer_features = pd.get_dummies(customer_features, columns=['Region'])\n",
    "\n",
    "# Normalize the numerical features\n",
    "scaler = StandardScaler()\n",
    "customer_features[['Recency', 'Frequency', 'Monetary']] = scaler.fit_transform(customer_features[['Recency', 'Frequency', 'Monetary']])\n",
    "\n",
    "# Display the first few rows of the engineered features\n",
    "print(customer_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development\n",
    "Develop the Lookalike Model using an appropriate algorithm and calculate similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Development\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Prepare the data for the lookalike model\n",
    "customer_features = customer_features[['CustomerID', 'Recency', 'Frequency', 'Monetary'] + [col for col in customer_features.columns if 'Region_' in col]]\n",
    "\n",
    "# Fit the Nearest Neighbors model\n",
    "nn_model = NearestNeighbors(n_neighbors=4, metric='euclidean')\n",
    "nn_model.fit(customer_features.drop(columns=['CustomerID']))\n",
    "\n",
    "# Function to find lookalikes for a given customer\n",
    "def find_lookalikes(customer_id):\n",
    "    customer_index = customer_features[customer_features['CustomerID'] == customer_id].index[0]\n",
    "    distances, indices = nn_model.kneighbors([customer_features.drop(columns=['CustomerID']).iloc[customer_index]])\n",
    "    lookalikes = customer_features.iloc[indices[0][1:]]\n",
    "    lookalikes['SimilarityScore'] = 1 / (1 + distances[0][1:])\n",
    "    return lookalikes[['CustomerID', 'SimilarityScore']]\n",
    "\n",
    "# Generate lookalikes for the first 20 customers\n",
    "lookalike_results = {}\n",
    "for customer_id in customers_df['CustomerID'][:20]:\n",
    "    lookalike_results[customer_id] = find_lookalikes(customer_id).values.tolist()\n",
    "\n",
    "# Save the lookalike results to a CSV file\n",
    "lookalike_df = pd.DataFrame.from_dict(lookalike_results, orient='index')\n",
    "lookalike_df.to_csv('FirstName_LastName_Lookalike.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 3 Lookalikes for First 20 Customers\n",
    "Generate the top 3 lookalikes with their similarity scores for the first 20 customers and save to Lookalike.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName SignupDate   Recency  Frequency  Monetary  \\\n",
      "0      C0001    Lawrence Carroll 2022-07-10 -0.266933  -0.011458 -0.061701   \n",
      "1      C0002      Elizabeth Lutz 2022-02-13 -0.690872  -0.467494 -0.877744   \n",
      "2      C0003      Michael Rivera 2024-03-07  0.722260  -0.467494 -0.405857   \n",
      "3      C0004  Kathleen Rodriguez 2022-10-09 -0.987630   1.356650  1.032547   \n",
      "4      C0005         Laura Weber 2022-08-15 -0.281064  -0.923530 -0.783929   \n",
      "\n",
      "   Region_Asia  Region_Europe  Region_North America  Region_South America  \n",
      "0        False          False                 False                  True  \n",
      "1         True          False                 False                 False  \n",
      "2        False          False                 False                  True  \n",
      "3        False          False                 False                  True  \n",
      "4         True          False                 False                 False  \n",
      "                                  0                             1  \\\n",
      "C0001   [C0152, 0.8442342445571209]   [C0107, 0.8235892774469206]   \n",
      "C0002   [C0142, 0.7284064516587945]   [C0146, 0.6903737428860262]   \n",
      "C0003   [C0052, 0.8531221755957277]   [C0192, 0.6656600386798343]   \n",
      "C0004   [C0012, 0.6843507574780322]   [C0113, 0.6791682296983892]   \n",
      "C0005   [C0186, 0.8227706486406565]   [C0177, 0.6557289782470027]   \n",
      "C0006   [C0158, 0.6894116150718859]   [C0168, 0.6642824940808202]   \n",
      "C0007   [C0027, 0.5502353464423353]   [C0043, 0.5337870509731606]   \n",
      "C0008   [C0109, 0.5038477356137047]   [C0098, 0.4759084880711163]   \n",
      "C0009   [C0198, 0.6816441995387141]   [C0121, 0.6671429184415919]   \n",
      "C0010   [C0199, 0.7450051542168716]   [C0166, 0.6595831063935662]   \n",
      "C0011   [C0137, 0.8201799165437649]   [C0048, 0.7668460771985323]   \n",
      "C0012   [C0004, 0.6843507574780322]   [C0155, 0.6146560309247667]   \n",
      "C0013   [C0155, 0.7358793600190114]   [C0104, 0.6429748220355451]   \n",
      "C0014  [C0058, 0.41141392027331836]  [C0020, 0.40615194542431926]   \n",
      "C0015   [C0036, 0.5388272134932665]   [C0042, 0.4802740416351615]   \n",
      "C0016   [C0183, 0.9574758543518692]   [C0072, 0.6703641987856555]   \n",
      "C0017   [C0051, 0.5808914802142512]   [C0075, 0.5670324768865304]   \n",
      "C0018    [C0079, 0.647909333871775]   [C0117, 0.6190473087037067]   \n",
      "C0019   [C0172, 0.8347042597196287]   [C0164, 0.5962453744014263]   \n",
      "C0020   [C0058, 0.7746654883148133]   [C0144, 0.4247982829958241]   \n",
      "\n",
      "                                  2  \n",
      "C0001   [C0048, 0.6546756569272248]  \n",
      "C0002    [C0159, 0.668778098562259]  \n",
      "C0003   [C0120, 0.6518756444882744]  \n",
      "C0004   [C0099, 0.5732582317321098]  \n",
      "C0005   [C0140, 0.6513782956130327]  \n",
      "C0006   [C0187, 0.6634672930121068]  \n",
      "C0007   [C0040, 0.5201293619224812]  \n",
      "C0008   [C0068, 0.4349261779438497]  \n",
      "C0009   [C0063, 0.6399536146439532]  \n",
      "C0010    [C0132, 0.648728846917786]  \n",
      "C0011   [C0190, 0.6981471806111187]  \n",
      "C0012   [C0113, 0.6107706652279719]  \n",
      "C0013   [C0163, 0.6387673681092652]  \n",
      "C0014  [C0110, 0.40483488388598987]  \n",
      "C0015  [C0094, 0.47351117228655004]  \n",
      "C0016   [C0067, 0.6293695842589672]  \n",
      "C0017   [C0041, 0.5232392558647604]  \n",
      "C0018   [C0154, 0.5003772018198783]  \n",
      "C0019   [C0111, 0.5942660494390911]  \n",
      "C0020  [C0014, 0.40615194542431926]  \n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Create features from customer and product information for the Lookalike Model\n",
    "\n",
    "# Calculate the recency of the last transaction for each customer\n",
    "latest_transaction_date = transactions_df.groupby('CustomerID')['TransactionDate'].max().reset_index()\n",
    "latest_transaction_date.columns = ['CustomerID', 'LastTransactionDate']\n",
    "latest_transaction_date['Recency'] = (transactions_df['TransactionDate'].max() - latest_transaction_date['LastTransactionDate']).dt.days\n",
    "\n",
    "# Calculate the frequency of transactions for each customer\n",
    "transaction_frequency = transactions_df.groupby('CustomerID')['TransactionID'].count().reset_index()\n",
    "transaction_frequency.columns = ['CustomerID', 'Frequency']\n",
    "\n",
    "# Calculate the monetary value of transactions for each customer\n",
    "transaction_monetary = transactions_df.groupby('CustomerID')['TotalValue'].sum().reset_index()\n",
    "transaction_monetary.columns = ['CustomerID', 'Monetary']\n",
    "\n",
    "# Merge the recency, frequency, and monetary features with the customer data\n",
    "customer_features = customers_df.merge(latest_transaction_date[['CustomerID', 'Recency']], on='CustomerID')\n",
    "customer_features = customer_features.merge(transaction_frequency[['CustomerID', 'Frequency']], on='CustomerID')\n",
    "customer_features = customer_features.merge(transaction_monetary[['CustomerID', 'Monetary']], on='CustomerID')\n",
    "\n",
    "# One-hot encode the 'Region' feature\n",
    "customer_features = pd.get_dummies(customer_features, columns=['Region'])\n",
    "\n",
    "# Normalize the numerical features\n",
    "scaler = StandardScaler()\n",
    "customer_features[['Recency', 'Frequency', 'Monetary']] = scaler.fit_transform(customer_features[['Recency', 'Frequency', 'Monetary']])\n",
    "\n",
    "# Display the first few rows of the engineered features\n",
    "print(customer_features.head())\n",
    "\n",
    "# Model Development\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Prepare the data for the lookalike model\n",
    "customer_features = customer_features[['CustomerID', 'Recency', 'Frequency', 'Monetary'] + [col for col in customer_features.columns if 'Region_' in col]]\n",
    "\n",
    "# Fit the Nearest Neighbors model\n",
    "nn_model = NearestNeighbors(n_neighbors=4, metric='euclidean')\n",
    "nn_model.fit(customer_features.drop(columns=['CustomerID']))\n",
    "\n",
    "# Function to find lookalikes for a given customer\n",
    "def find_lookalikes(customer_id):\n",
    "    customer_index = customer_features[customer_features['CustomerID'] == customer_id].index[0]\n",
    "    distances, indices = nn_model.kneighbors([customer_features.drop(columns=['CustomerID']).iloc[customer_index]])\n",
    "    lookalikes = customer_features.iloc[indices[0][1:]]\n",
    "    lookalikes['SimilarityScore'] = 1 / (1 + distances[0][1:])\n",
    "    return lookalikes[['CustomerID', 'SimilarityScore']]\n",
    "\n",
    "# Generate lookalikes for the first 20 customers\n",
    "lookalike_results = {}\n",
    "for customer_id in customers_df['CustomerID'][:20]:\n",
    "    lookalike_results[customer_id] = find_lookalikes(customer_id).values.tolist()\n",
    "\n",
    "# Save the lookalike results to a CSV file\n",
    "lookalike_df = pd.DataFrame.from_dict(lookalike_results, orient='index')\n",
    "print(lookalike_df)\n",
    "lookalike_df.to_csv('FirstName_LastName_Lookalike.csv', header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
